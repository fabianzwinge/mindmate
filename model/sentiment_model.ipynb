{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18b55b6",
   "metadata": {},
   "source": [
    "## Prerequisites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "416faea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "source": [
    "#pip install transformers datasets torch scikit-learn huggingface_hub langdetect accelerate tf-keras\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ea12a3",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef750869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "dataset = load_dataset(\"Sp1786/multiclass-sentiment-analysis-dataset\")\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "val_ds   = dataset[\"validation\"]\n",
    "test_ds  = dataset[\"test\"]\n",
    "\n",
    "#DOWNSAMPLE DATASET FOR FASTER EXPERIMENTATION\n",
    "# train_df = pd.DataFrame(dataset[\"train\"])\n",
    "# val_df   = pd.DataFrame(dataset[\"validation\"])\n",
    "# test_df  = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "# # Reduce size due to resource constraints\n",
    "# train_size = 20000\n",
    "# val_size   = 5000\n",
    "# test_size  = 5000\n",
    "\n",
    "# def reduce_sample(df, n, seed=42):\n",
    "#     return df.groupby(\"label\", group_keys=False).apply(\n",
    "#         lambda x: x.sample(frac=n/len(df), random_state=seed)\n",
    "#     ).reset_index(drop=True).sample(frac=1, random_state=seed)\n",
    "\n",
    "# def reduce_sample_balanced(df, n_per_class, seed=42):\n",
    "#     return pd.concat([\n",
    "#         df[df['label'] == l].sample(n=n_per_class//len(df['label'].unique()), random_state=seed)\n",
    "#         for l in df['label'].unique()\n",
    "#     ]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "#train_small = reduce_sample(train_df, train_size)\n",
    "#val_small   = reduce_sample(val_df, val_size)\n",
    "#test_small  = reduce_sample(test_df, test_size)\n",
    "\n",
    "# train_small = reduce_sample_balanced(train_df, train_size)\n",
    "# val_small   = reduce_sample_balanced(val_df, val_size)\n",
    "# test_small  = reduce_sample_balanced(test_df, test_size)\n",
    "\n",
    "# train_ds = Dataset.from_pandas(train_small,preserve_index=False)\n",
    "# val_ds   = Dataset.from_pandas(val_small,preserve_index=False)\n",
    "# test_ds  = Dataset.from_pandas(test_small,preserve_index=False)\n",
    "\n",
    "# dataset_reduced = DatasetDict({\n",
    "#     \"train\": train_ds,\n",
    "#     \"validation\": val_ds,\n",
    "#     \"test\": test_ds\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb5c9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 9536, 'text': 'Cooking microwave pizzas, yummy', 'label': 2, 'sentiment': 'positive'}\n",
      "---\n",
      "{'id': 6135, 'text': 'Any plans of allowing sub tasks to show up in the widget?', 'label': 1, 'sentiment': 'neutral'}\n",
      "---\n",
      "{'id': 17697, 'text': \" I love the humor, I just reworded it. Like saying 'group therapy' instead`a 'gang banging'. Keeps my moms off my back.   Hahaha\", 'label': 2, 'sentiment': 'positive'}\n",
      "---\n",
      "{'id': 14182, 'text': ' naw idk what ur talkin about', 'label': 1, 'sentiment': 'neutral'}\n",
      "---\n",
      "{'id': 17840, 'text': ' That sucks to hear. I hate days like that', 'label': 0, 'sentiment': 'negative'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(train_ds[i])\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1b9d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts:\n",
      "Counter({1: 11649, 2: 10478, 0: 9105})\n",
      "\n",
      "Validation class counts:\n",
      "Counter({1: 1928, 2: 1760, 0: 1517})\n",
      "\n",
      "Test class counts:\n",
      "Counter({1: 1930, 2: 1730, 0: 1546})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Train class counts:\")\n",
    "print(Counter(train_ds['label']))\n",
    "\n",
    "print(\"\\nValidation class counts:\")\n",
    "print(Counter(val_ds['label']))\n",
    "\n",
    "print(\"\\nTest class counts:\")\n",
    "print(Counter(test_ds['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1931308",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05dc139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "def reduce_lengthening(text: str) -> str:\n",
    "    # \"looooove\" -> \"loove\"\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "\n",
    "def clean_tweet(text: str, remove_hashtags=False) -> str:\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "    text = re.sub(r\"@\\w+\", \" \", text)\n",
    "    if remove_hashtags:\n",
    "        text = re.sub(r\"#\\w+\", \" \", text)\n",
    "    text = re.sub(r\"[^0-9A-Za-z\\s\\.\\,\\!\\?\\:\\;\\-\\'\\\"]\", \" \", text)\n",
    "    text = reduce_lengthening(text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except:\n",
    "        lang = \"unknown\"\n",
    "\n",
    "    if lang != \"en\":\n",
    "        return \"\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def apply_cleaning(ds: Dataset) -> Dataset:\n",
    "    ds = ds.map(lambda ex: {\"clean_text\": clean_tweet(ex[\"text\"])}, batched=False)\n",
    "    ds = ds.filter(lambda ex: ex[\"clean_text\"] != \"\")\n",
    "    return ds\n",
    "\n",
    "train_ds = apply_cleaning(train_ds)\n",
    "val_ds   = apply_cleaning(val_ds)\n",
    "test_ds  = apply_cleaning(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3460626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 9536, 'text': 'Cooking microwave pizzas, yummy', 'label': 2, 'sentiment': 'positive', 'clean_text': 'cooking microwave pizzas, yummy'}\n",
      "---\n",
      "{'id': 6135, 'text': 'Any plans of allowing sub tasks to show up in the widget?', 'label': 1, 'sentiment': 'neutral', 'clean_text': 'any plans of allowing sub tasks to show up in the widget?'}\n",
      "---\n",
      "{'id': 17697, 'text': \" I love the humor, I just reworded it. Like saying 'group therapy' instead`a 'gang banging'. Keeps my moms off my back.   Hahaha\", 'label': 2, 'sentiment': 'positive', 'clean_text': \"i love the humor, i just reworded it. like saying 'group therapy' instead a 'gang banging'. keeps my moms off my back. hahaha\"}\n",
      "---\n",
      "{'id': 14182, 'text': ' naw idk what ur talkin about', 'label': 1, 'sentiment': 'neutral', 'clean_text': 'naw idk what ur talkin about'}\n",
      "---\n",
      "{'id': 17840, 'text': ' That sucks to hear. I hate days like that', 'label': 0, 'sentiment': 'negative', 'clean_text': 'that sucks to hear. i hate days like that'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(train_ds[i])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bfb052",
   "metadata": {},
   "source": [
    "## Tokenisation and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29ecf23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4772/4772 [00:00<00:00, 23628.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LENGTH = 64 \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"clean_text\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds   = val_ds.map(tokenize, batched=True)\n",
    "test_ds  = test_ds.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9467812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 9536, 'text': 'Cooking microwave pizzas, yummy', 'label': 2, 'sentiment': 'positive', 'clean_text': 'cooking microwave pizzas, yummy', 'input_ids': [101, 8434, 18302, 10733, 2015, 1010, 9805, 18879, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "---\n",
      "{'id': 6135, 'text': 'Any plans of allowing sub tasks to show up in the widget?', 'label': 1, 'sentiment': 'neutral', 'clean_text': 'any plans of allowing sub tasks to show up in the widget?', 'input_ids': [101, 2151, 3488, 1997, 4352, 4942, 8518, 2000, 2265, 2039, 1999, 1996, 15536, 24291, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "---\n",
      "{'id': 17697, 'text': \" I love the humor, I just reworded it. Like saying 'group therapy' instead`a 'gang banging'. Keeps my moms off my back.   Hahaha\", 'label': 2, 'sentiment': 'positive', 'clean_text': \"i love the humor, i just reworded it. like saying 'group therapy' instead a 'gang banging'. keeps my moms off my back. hahaha\", 'input_ids': [101, 1045, 2293, 1996, 8562, 1010, 1045, 2074, 2128, 18351, 2098, 2009, 1012, 2066, 3038, 1005, 2177, 7242, 1005, 2612, 1037, 1005, 6080, 22255, 1005, 1012, 7906, 2026, 3566, 2015, 2125, 2026, 2067, 1012, 5292, 3270, 3270, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "---\n",
      "{'id': 14182, 'text': ' naw idk what ur talkin about', 'label': 1, 'sentiment': 'neutral', 'clean_text': 'naw idk what ur talkin about', 'input_ids': [101, 6583, 2860, 8909, 2243, 2054, 24471, 2831, 2378, 2055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "---\n",
      "{'id': 17840, 'text': ' That sucks to hear. I hate days like that', 'label': 0, 'sentiment': 'negative', 'clean_text': 'that sucks to hear. i hate days like that', 'input_ids': [101, 2008, 19237, 2000, 2963, 1012, 1045, 5223, 2420, 2066, 2008, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(train_ds[i])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc969888",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c45eeb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "NUM_LABELS = 3\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=NUM_LABELS,\n",
    "    dropout=0.2,\n",
    "    attention_dropout=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ba81a",
   "metadata": {},
   "source": [
    "## Trainer Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca177b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sentiment_model\",\n",
    "    eval_strategy=\"steps\",     \n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,           \n",
    "    learning_rate=2e-5,                \n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,                \n",
    "    weight_decay=0.05,                \n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,                \n",
    "    load_best_model_at_end=True,      \n",
    "    metric_for_best_model=\"f1\",      \n",
    "    greater_is_better=True,           \n",
    "    warmup_steps=200,                 \n",
    "    lr_scheduler_type=\"linear\"    \n",
    ")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e5d050",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88c271ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='10749' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7500/10749 1:31:53 < 39:49, 1.36 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.688081</td>\n",
       "      <td>0.699497</td>\n",
       "      <td>0.694585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.655270</td>\n",
       "      <td>0.725063</td>\n",
       "      <td>0.723860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.627889</td>\n",
       "      <td>0.738265</td>\n",
       "      <td>0.737986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.614454</td>\n",
       "      <td>0.741618</td>\n",
       "      <td>0.741494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.613964</td>\n",
       "      <td>0.740151</td>\n",
       "      <td>0.740127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.609508</td>\n",
       "      <td>0.744552</td>\n",
       "      <td>0.744115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.622961</td>\n",
       "      <td>0.750210</td>\n",
       "      <td>0.749218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>0.615914</td>\n",
       "      <td>0.743085</td>\n",
       "      <td>0.744770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.622855</td>\n",
       "      <td>0.752515</td>\n",
       "      <td>0.751239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.522900</td>\n",
       "      <td>0.648163</td>\n",
       "      <td>0.751886</td>\n",
       "      <td>0.751022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>0.629749</td>\n",
       "      <td>0.756706</td>\n",
       "      <td>0.757048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.548200</td>\n",
       "      <td>0.606135</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>0.755873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.624965</td>\n",
       "      <td>0.757963</td>\n",
       "      <td>0.758636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.614861</td>\n",
       "      <td>0.757544</td>\n",
       "      <td>0.757713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>0.654769</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>0.753612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback, get_scheduler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "num_training_steps = len(train_ds) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "\n",
    "trainer.train() \n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=trainer.optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d57b32",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3572ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fzw\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.6235312819480896, 'test_accuracy': 0.7620841180163214, 'test_f1': 0.7620346883481925, 'test_runtime': 72.6152, 'test_samples_per_second': 65.813, 'test_steps_per_second': 8.235}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.80      0.78      1436\n",
      "     neutral       0.70      0.69      0.69      1740\n",
      "    positive       0.84      0.81      0.82      1603\n",
      "\n",
      "    accuracy                           0.76      4779\n",
      "   macro avg       0.76      0.77      0.76      4779\n",
      "weighted avg       0.76      0.76      0.76      4779\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_output = trainer.predict(test_ds)\n",
    "print(test_output.metrics)\n",
    "\n",
    "preds = np.argmax(test_output.predictions, axis=1)\n",
    "labels = test_output.label_ids\n",
    "print(classification_report(labels, preds, labels=[0,1,2], target_names=[\"negative\",\"neutral\",\"positive\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001cddc",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06865c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model & tokenizer saved to ./sentiment_model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "SAVE_DIR = \"./sentiment_model\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "trainer.save_model(SAVE_DIR)             \n",
    "tokenizer.save_pretrained(SAVE_DIR)\n",
    "print(\"Model & tokenizer saved to\", SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6e9b3",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: tensor([0, 1, 2])\n",
      "Probabilities:\n",
      " tensor([[0.9818, 0.0150, 0.0031],\n",
      "        [0.0484, 0.7578, 0.1938],\n",
      "        [0.0038, 0.0072, 0.9890]], grad_fn=<SoftmaxBackward0>)\n",
      "Confidences: tensor([0.9818, 0.7578, 0.9890], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "inputs = [\n",
    "    \"Im feeling bad\",        # Negative sentiment\n",
    "    \"Im feeling neutral\",    # Neutral sentiment\n",
    "    \"I absolutely love this\" # Positive sentiment\n",
    "]\n",
    "\n",
    "tokenized_inputs = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "outputs = model(**tokenized_inputs)\n",
    "logits = outputs.logits\n",
    "\n",
    "predictions = torch.argmax(logits, axis=1)\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "confidences = torch.max(probs, axis=1).values\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Probabilities:\\n\", probs)\n",
    "print(\"Confidences:\", confidences)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
